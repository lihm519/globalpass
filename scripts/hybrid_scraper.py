#!/usr/bin/env python3
"""
GlobalPass æ··åˆçˆ¬è™«
- Airalo: ä½¿ç”¨ Playwrightï¼ˆè·å– JavaScript æ¸²æŸ“åçš„ hint å±æ€§ï¼‰
- Nomad: ä½¿ç”¨ BeautifulSoupï¼ˆé¡µé¢ç»“æ„ç®€å•ï¼‰
"""

import json
import logging
import re
import requests
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Supabase é…ç½®
SUPABASE_URL = "https://mzodnvjtlujvvwfnpcyb.supabase.co"
SERVICE_ROLE_KEY = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im16b2Rudmp0bHVqdnZ3Zm5wY3liIiwicm9sZSI6InNlcnZpY2Vfcm9sZSIsImlhdCI6MTc2NzU0MDk4NiwiZXhwIjoyMDgzMTE2OTg2fQ.gr-5J22EhV08PLghNcoS8o5lUFjaEyby21MwE-35ENs"

# å¤‡ç”¨å›ºå®šæ±‡ç‡
FALLBACK_EXCHANGE_RATES = {
    "EUR": 1.17,
    "SGD": 0.78
}

class HybridScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        self.exchange_rates = self.get_exchange_rates()
    
    def get_exchange_rates(self) -> Dict[str, float]:
        """è·å–å®æ—¶æ±‡ç‡"""
        try:
            logger.info("ğŸ“Š æ­£åœ¨è·å–å®æ—¶æ±‡ç‡...")
            response = self.session.get("https://open.er-api.com/v6/latest/USD", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                rates = data['rates']
                
                # è®¡ç®— EUR å’Œ SGD å¯¹ USD çš„æ±‡ç‡
                exchange_rates = {
                    "EUR": round(1 / rates['EUR'], 4),  # EUR to USD
                    "SGD": round(1 / rates['SGD'], 4)   # SGD to USD
                }
                
                logger.info(f"âœ… å®æ—¶æ±‡ç‡è·å–æˆåŠŸ:")
                logger.info(f"   EUR: {exchange_rates['EUR']}")
                logger.info(f"   SGD: {exchange_rates['SGD']}")
                logger.info(f"   æ›´æ–°æ—¶é—´: {data['time_last_update_utc']}")
                
                return exchange_rates
            else:
                logger.warning(f"âš ï¸ æ±‡ç‡ API è¿”å›é”™è¯¯: {response.status_code}")
                logger.warning(f"   ä½¿ç”¨å¤‡ç”¨å›ºå®šæ±‡ç‡")
                return FALLBACK_EXCHANGE_RATES
        except Exception as e:
            logger.error(f"âŒ è·å–å®æ—¶æ±‡ç‡å¤±è´¥: {e}")
            logger.warning(f"   ä½¿ç”¨å¤‡ç”¨å›ºå®šæ±‡ç‡")
            return FALLBACK_EXCHANGE_RATES
    
    def convert_to_usd(self, price: float, currency: str) -> float:
        """å°†ä»·æ ¼è½¬æ¢ä¸ºç¾å…ƒ"""
        rate = self.exchange_rates.get(currency, 1.0)
        return round(price * rate, 2)
    
    def load_countries(self) -> List[Dict]:
        """åŠ è½½å›½å®¶é…ç½®"""
        config_file = Path(__file__).parent.parent / "config" / "countries.json"
        
        if not config_file.exists():
            logger.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return []
        
        with open(config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def scrape_airalo_with_playwright(self, country: Dict) -> List[Dict]:
        """ä½¿ç”¨ Playwright æŠ“å– Airalo æ•°æ®"""
        try:
            url = f"https://www.airalo.com/{country['airalo_slug']}-esim"
            
            logger.info(f"ğŸŒ æ­£åœ¨æŠ“å– Airalo - {country['name']} (Playwright)...")
            
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()
                page.goto(url, wait_until="networkidle", timeout=30000)
                
                # ç­‰å¾…å¥—é¤åŠ è½½
                page.wait_for_selector('a[hint*="Select"]', timeout=10000)
                
                # è·å–æ‰€æœ‰åŒ…å« hint å±æ€§çš„é“¾æ¥
                links = page.query_selector_all('a[hint*="Select"]')
                
                packages = []
                for link in links:
                    hint = link.get_attribute('hint')
                    
                    if not hint:
                        continue
                    
                    # è§£æ hint: "Select 1 GB - 3 Days for $4.00 USD."
                    match = re.match(r'Select\s+(\d+)\s*GB\s*-\s*(\d+)\s*Days?\s+for\s+\$?([\d.]+)\s*USD', hint)
                    
                    if match:
                        data_amount = match.group(1)
                        validity_days = match.group(2)
                        price_usd = float(match.group(3))
                        validity = f"{validity_days} Day" if validity_days == "1" else f"{validity_days} Days"
                        
                        package = {
                            "provider": "Airalo",
                            "country": country['name'],
                            "plan_name": f"{country['name']} {data_amount}GB {validity}",
                            "data_type": "Data",
                            "data_amount": f"{data_amount}GB",
                            "validity": validity,
                            "price": price_usd,
                            "network": "Local Operators",
                            "link": url,
                            "raw_data": json.dumps({
                                "original_price": price_usd,
                                "original_currency": "USD",
                                "usd_price": price_usd,
                                "currency": "USD",
                                "data": f"{data_amount}GB",
                                "validity": validity,
                            }),
                            "last_checked": datetime.utcnow().isoformat(),
                        }
                        packages.append(package)
                        logger.debug(f"   âœ… {data_amount}GB {validity} - ${price_usd}")
                
                browser.close()
                
                logger.info(f"âœ… Airalo {country['name']}: è·å– {len(packages)} ä¸ªå¥—é¤")
                return packages
                
        except Exception as e:
            logger.error(f"âŒ Airalo {country['name']}: {e}")
            return []
    
    def scrape_nomad_with_bs4(self, country: Dict) -> List[Dict]:
        """ä½¿ç”¨ BeautifulSoup æŠ“å– Nomad æ•°æ®"""
        try:
            url = f"https://www.getnomad.app/shop?country={country['nomad_code']}"
            
            logger.info(f"ğŸŒ æ­£åœ¨æŠ“å– Nomad - {country['name']} (BeautifulSoup)...")
            
            response = self.session.get(url, timeout=15)
            
            if response.status_code != 200:
                logger.warning(f"âŒ Nomad {country['name']}: HTTP {response.status_code}")
                return []
            
            soup = BeautifulSoup(response.content, 'html.parser')
            packages = []
            
            # æŸ¥æ‰¾æ‰€æœ‰å¥—é¤å®¹å™¨
            plan_containers = soup.find_all('div', class_=re.compile(r'plan|package|card'))
            
            for container in plan_containers:
                text = container.get_text(strip=True)
                
                # è§£ææ ‡å‡†å¥—é¤: "1 GB For 7 DAYS USD 4"
                standard_match = re.search(r'(\d+)\s*GB.*?(\d+)\s*DAYS.*?USD\s*([\d.]+)', text, re.IGNORECASE)
                
                if standard_match:
                    data_amount = standard_match.group(1)
                    validity_days = standard_match.group(2)
                    price_usd = float(standard_match.group(3))
                    validity = f"{validity_days} Day" if validity_days == "1" else f"{validity_days} Days"
                    
                    package = {
                        "provider": "Nomad",
                        "country": country['name'],
                        "plan_name": f"{country['name']} {data_amount} GB {validity}",
                        "data_type": "Data",
                        "data_amount": f"{data_amount}GB",
                        "validity": validity,
                        "price": price_usd,
                        "network": "Local Operators",
                        "link": url,
                        "raw_data": json.dumps({
                            "original_price": price_usd,
                            "original_currency": "USD",
                            "usd_price": price_usd,
                            "currency": "USD",
                            "data": f"{data_amount}GB",
                            "validity": validity,
                        }),
                        "last_checked": datetime.utcnow().isoformat(),
                    }
                    packages.append(package)
                    logger.debug(f"   âœ… {data_amount}GB {validity} - ${price_usd}")
                
                # è§£ææ— é™æµé‡å¥—é¤: "Unlimited 3 DAYS USD 11"
                unlimited_match = re.search(r'Unlimited.*?(\d+)\s*DAYS.*?USD\s*([\d.]+)', text, re.IGNORECASE)
                
                if unlimited_match:
                    validity_days = unlimited_match.group(1)
                    price_usd = float(unlimited_match.group(2))
                    validity = f"{validity_days} Day" if validity_days == "1" else f"{validity_days} Days"
                    
                    package = {
                        "provider": "Nomad",
                        "country": country['name'],
                        "plan_name": f"{country['name']} Unlimited {validity}",
                        "data_type": "Unlimited",
                        "data_amount": "Unlimited",
                        "validity": validity,
                        "price": price_usd,
                        "network": "Local Operators",
                        "link": url,
                        "raw_data": json.dumps({
                            "original_price": price_usd,
                            "original_currency": "USD",
                            "usd_price": price_usd,
                            "currency": "USD",
                            "data": "Unlimited",
                            "validity": validity,
                        }),
                        "last_checked": datetime.utcnow().isoformat(),
                    }
                    packages.append(package)
                    logger.debug(f"   âœ… Unlimited {validity} - ${price_usd}")
            
            logger.info(f"âœ… Nomad {country['name']}: è·å– {len(packages)} ä¸ªå¥—é¤")
            return packages
            
        except Exception as e:
            logger.error(f"âŒ Nomad {country['name']}: {e}")
            return []
    
    def update_database(self, packages: List[Dict]) -> None:
        """æ›´æ–°æ•°æ®åº“"""
        headers = {
            "apikey": SERVICE_ROLE_KEY,
            "Authorization": f"Bearer {SERVICE_ROLE_KEY}",
            "Content-Type": "application/json",
            "Prefer": "resolution=merge-duplicates"
        }
        
        success_count = 0
        fail_count = 0
        
        for package in packages:
            try:
                response = requests.post(
                    f"{SUPABASE_URL}/rest/v1/esim_packages",
                    headers=headers,
                    json=package,
                    timeout=10
                )
                
                if response.status_code in [200, 201, 204]:
                    success_count += 1
                else:
                    fail_count += 1
                    logger.debug(f"   æ›´æ–°å¤±è´¥: {package['plan_name']} - HTTP {response.status_code}")
                    
            except Exception as e:
                fail_count += 1
                logger.debug(f"   æ›´æ–°å¤±è´¥: {package['plan_name']} - {e}")
        
        logger.info(f"ğŸ“Š æ•°æ®åº“æ›´æ–°å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {fail_count}")
    
    def run(self):
        """è¿è¡Œçˆ¬è™«"""
        logger.info("="*70)
        logger.info("ğŸš€ GlobalPass æ··åˆçˆ¬è™«å¯åŠ¨")
        logger.info("="*70)
        
        countries = self.load_countries()
        
        if not countries:
            logger.error("âŒ æ²¡æœ‰æ‰¾åˆ°å›½å®¶é…ç½®")
            return
        
        logger.info(f"ğŸ“ åŠ è½½ {len(countries)} ä¸ªå›½å®¶é…ç½®")
        
        all_packages = []
        
        for country in countries:
            # æŠ“å– Airalo æ•°æ®ï¼ˆä½¿ç”¨ Playwrightï¼‰
            airalo_packages = self.scrape_airalo_with_playwright(country)
            all_packages.extend(airalo_packages)
            
            # æŠ“å– Nomad æ•°æ®ï¼ˆä½¿ç”¨ BeautifulSoupï¼‰
            nomad_packages = self.scrape_nomad_with_bs4(country)
            all_packages.extend(nomad_packages)
        
        logger.info("="*70)
        logger.info(f"ğŸ“Š æŠ“å–å®Œæˆ:")
        logger.info(f"   - æ€»å¥—é¤æ•°: {len(all_packages)}")
        logger.info("="*70)
        
        # æ›´æ–°æ•°æ®åº“
        if all_packages:
            logger.info("ğŸ’¾ æ­£åœ¨æ›´æ–°æ•°æ®åº“...")
            self.update_database(all_packages)
        
        logger.info("="*70)
        logger.info("âœ… çˆ¬è™«è¿è¡Œå®Œæˆ")
        logger.info("="*70)

if __name__ == "__main__":
    scraper = HybridScraper()
    scraper.run()
